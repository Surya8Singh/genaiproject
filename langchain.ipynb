{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/503934342.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)\n"
     ]
    }
   ],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/2739170393.py:3: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm.predict(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the capital of India\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/3991958384.py:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})\n",
      "/Users/suryapratapsingh/Desktop/AIProjects/QABot/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moscow\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you tell me the capital of Russia\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nIn the world of technology,\\nLies a concept so new,\\nArtificial intelligence,\\nCreating something out of the blue.\\n\\nA creation of human minds,\\nBut with a mind of its own,\\nAI, a marvel of science,\\nThat continues to grow and evolve.\\n\\nWith algorithms and codes,\\nIt learns and adapts,\\nPerforming tasks with precision,\\nAnd making our lives intact.\\n\\nFrom self-driving cars,\\nTo virtual assistants,\\nAI has revolutionized,\\nThe way we exist.\\n\\nBut with great power,\\nComes great responsibility,\\nFor who can control,\\nThis advanced ability?\\n\\nSome fear its potential,\\nTo surpass human control,\\nBut others see its potential,\\nTo help us reach our goals.\\n\\nIn a world of endless possibilities,\\nAI is a leap of faith,\\nA tool to enhance our lives,\\nAnd take us to a new state.\\n\\nBut as we journey into the unknown,\\nLet us not forget,\\nThat AI is a reflection,\\nOf our own intellect.\\n\\nSo let us use it wisely,\\nAnd continue to explore,\\nFor AI is a creation,\\nThat we cannot ignore.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates And LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this India'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Tell me the capital of this {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/1502807403.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain=LLMChain(llm=llm,prompt=prompt_template)\n",
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/1502807403.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(chain.run(\"India\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Uing simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"Suggest me some amazing places to visit in {capital}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain=LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Here are some amazing places to visit in New Delhi:\\n\\n1. Red Fort - A historic fort built in the 17th century, known for its beautiful architecture and rich history.\\n\\n2. Qutub Minar - A UNESCO World Heritage Site and the tallest minaret in India, dating back to the 12th century.\\n\\n3. India Gate - A war memorial dedicated to the Indian soldiers who died in World War I, surrounded by lush green lawns and a popular picnic spot.\\n\\n4. Lotus Temple - A Bahá'í House of Worship known for its stunning lotus-shaped architecture and peaceful ambiance.\\n\\n5. Humayun's Tomb - Another UNESCO World Heritage Site, this 16th-century mausoleum is a beautiful example of Mughal architecture.\\n\\n6. Chandni Chowk - One of the oldest and busiest markets in Delhi, perfect for shopping and trying out delicious street food.\\n\\n7. Akshardham Temple - A magnificent Hindu temple complex known for its intricate carvings and beautiful gardens.\\n\\n8. Jama Masjid - The largest mosque in India, built by Mughal emperor Shah Jahan in the 17th century.\\n\\n9. National Gallery of Modern Art - A must-visit for art lovers, this museum showcases a vast\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template=PromptTemplate(input_variables=['country'],\n",
    "template=\"Please tell me the capital of the {country}\")\n",
    "\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_template,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template=PromptTemplate(input_variables=['capital'],\n",
    "template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain=LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain=SequentialChain(chains=[capital_chain,famous_chain],\n",
    "input_variables=['country'],\n",
    "output_variables=['capital',\"places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/1911137727.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({'country':\"India\"})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 'India',\n",
       " 'capital': '\\n\\nThe capital of India is New Delhi. ',\n",
       " 'places': \"\\n1. Red Fort - a historic fort and UNESCO World Heritage Site\\n2. Qutub Minar - the tallest brick minaret in the world\\n3. Humayun's Tomb - a stunning Mughal-era mausoleum\\n4. India Gate - a war memorial and iconic landmark\\n5. Lotus Temple - a Bahá'í House of Worship with a unique lotus-shaped architecture\\n6. Jama Masjid - one of the largest mosques in India\\n7. Chandni Chowk - a bustling market and foodie paradise\\n8. Akshardham Temple - a magnificent Hindu temple with intricate carvings and a water show\\n9. National Gallery of Modern Art - showcasing contemporary Indian art\\n10. Dilli Haat - a cultural hub with handicrafts, food, and performances from all over India.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/3767606333.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')\n"
     ]
    }
   ],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/ipykernel_58468/600681441.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chatllm([\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"AI: Making us question our intelligence since 1956.\"\\n2. \"Why did the AI break up with its computer? It just couldn\\'t handle the bytes anymore.\"\\n3. \"AI\\'s favorite pickup line: \\'Are you a software update? Because you make my heart skip a beat.\\'\"\\n4. \"AI\\'s idea of a romantic date? A candlelit dinner with a spreadsheet.\"\\n5. \"Why did the AI go to therapy? It had too many unresolved issues with its algorithms.\"\\n6. \"AI\\'s version of a midlife crisis? Upgrading to a newer model of itself.\"\\n7. \"AI\\'s favorite song? \\'I Will Always Debug You.\\'\"\\n8. \"AI\\'s worst fear? Getting a virus from a bad download.\"\\n9. \"Why did the AI go to the comedy club? To work on its artificial laughter.\"\\n10. \"AI\\'s dream job? Being a stand-up comedian, because it\\'s always looking for the best punchline.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 27, 'total_tokens': 228, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-30045f3c-a73a-443d-92de-07e2a5f61d68-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' sharp', ' astute']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variables: environ({'COMMAND_MODE': 'unix2003', 'HOME': '/Users/suryapratapsingh', 'LOGNAME': 'suryapratapsingh', 'MallocNanoZone': '0', 'OLDPWD': '/', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'PATH': '/Users/suryapratapsingh/Desktop/AIProjects/QABot/venv/bin:/opt/anaconda3/condabin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin', 'PWD': '/', 'SHELL': '/bin/zsh', 'SHLVL': '2', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.yhWp3NBMR9/Listeners', 'TMPDIR': '/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/', 'USER': 'suryapratapsingh', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_CODE_CACHE_PATH': '/Users/suryapratapsingh/Library/Application Support/Code/CachedData/38c31bc77e0dd6ae88a4e9cc93428cc27a56ba40', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': '/', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '/Users/suryapratapsingh/Library/Application Support/Code/1.93-main.sock', 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en-gb\",\"osLocale\":\"en-in\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/private/var/folders/0f/pyd2ygbs6f3d4zq4v501y0tc0000gn/T/AppTranslocation/25949973-BC79-453C-831A-64D9DB4D4F23/d/Visual Studio Code.app/Contents/Resources/app/out/nls.messages.json\",\"locale\":\"en-gb\",\"availableLanguages\":{}}', 'VSCODE_PID': '54783', 'XPC_FLAGS': '0x0', 'XPC_SERVICE_NAME': '0', '_': '/Users/suryapratapsingh/Desktop/AIProjects/QABot/venv/bin/python', '__CFBundleIdentifier': 'com.microsoft.VSCode', '__CF_USER_TEXT_ENCODING': '0x1F5:0x0:0x0', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_L10N_BUNDLE_LOCATION': '', 'CONDA_SHLVL': '2', 'CONDA_PROMPT_MODIFIER': '(/Users/suryapratapsingh/Desktop/AIProjects/QABot/venv) ', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'utf-8', 'CONDA_EXE': '/opt/anaconda3/bin/conda', '_CE_CONDA': '', 'CONDA_PREFIX_1': '/opt/anaconda3', 'CONDA_ROOT': '/opt/anaconda3', 'CONDA_PREFIX': '/Users/suryapratapsingh/Desktop/AIProjects/QABot/venv', '_CE_M': '', 'CONDA_ALLOW_SOFTLINKS': 'false', 'CONDA_PYTHON_EXE': '/opt/anaconda3/bin/python', 'LC_CTYPE': 'UTF-8', 'CONDA_DEFAULT_ENV': '/Users/suryapratapsingh/Desktop/AIProjects/QABot/venv', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHON_FROZEN_MODULES': 'on', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'OPEN_API_KEY': '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', 'HUGGINGFACEHUB_API_TOKEN': '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'})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Environment Variables:\", os.environ)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
